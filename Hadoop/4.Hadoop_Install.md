# 하둡 설치 windows

## Java8 설치
https://www.oracle.com/java/technologies/downloads/#java8-windows

## hadoop 설치
[https://hadoop.apache.org/](https://dlcdn.apache.org/hadoop/common/hadoop-3.3.2/)
실습을 위해 3.3.2버전 다운로드 "hadoop-3.3.2.tar.gz" 설치
C드라이브 최상단에 압축 해제

## 환경변수 설정
1. "시스템 환경 변수 설정"창 열기
2. 사용자 변수 새로 만들기 -> 변수이름 : JAVA_HOME 변수 값 : C:\Progra∼1\Java\jdk1.8.0_351
3. 사용자 변수 새로 만들기 -> 변수이름 : HADOOP_HOME 변수 값 : C:\hadoop-3.3.2
4. 시스템 변수 중 "Path" 항목 더블클릭 -> 새로만들기 -> C:\Progra∼1\Java\jdk1.8.0_351\bin
5. 시스템 변수 중 "Path" 항목 더블클릭 -> 새로만들기 -> C:\hadoop-3.3.2\bin
6. window + R -> cmd -> hadoop입력 후 정상작동 하는지 확인
```
오류 자바 환경변수 오류  
C:\hadoop-3.3.2\etc\hadoop\hadoop-env.cmd 을 txt로 열어서  
25번째줄을 수정해준다. set JAVA_HOME="C:\Program Files\Java\jdk1.8.0_131"  
```
## 설정 파일 수정
C:\hadoop-3.3.2\etc\hadoop\core-site.xml
```
<configuration>
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://localhost:9000</value>
    </property>
</configuration>
```
C:\hadoop-3.3.2\etc\hadoop\hdfs-site.xml  
hadoop-3.3.2 하위에 dfs/data, dfs/name폴더를 직접 생성해야함
```
<configuration>
    <property>
        <name>dfs.replication</name>
        <value>1</value>
    </property>
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>/hadoop-3.3.2/dfs/name</value>
    </property>
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>/hadoop-3.3.2/dfs/data</value>
    </property>
</configuration>
```
C:\hadoop-3.3.2\etc\hadoop\mapred-site.xml
```
<configuration>
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
</configuration>
```
C:\hadoop-3.3.2\etc\hadoop\yarn-site.xml
```
<configuration>
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
    <property>
        <name>yarn.nodemanager.env-whitelist</name>
        <value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_HOME,PATH,LANG,TZ,HADOOP_MAPRED_HOME</value>
    </property>
</configuration>
```

## Hadoop 실행을 위한 winutils 설치
1. 다운로드 [[https://github.com/kontext-tech/winutils](https://github.com/kontext-tech/winutils/tree/master/hadoop-3.3.1/bin)](https://github.com/kontext-tech/winutils/archive/refs/heads/master.zip)  
2. 압축풀고 3.3.1/bin 안에 있는 파일을 C:hadoop-3.3.2/bin에 덮어씌우기
3. cmd 관리자모드 실행
4. 하둡 폴더로 이동
```
$ cd C:\hadoop-3.3.2
```
5. hdfs namenode 실행
```
$ hdfs namenode -format
```
6. hdfs 시작
```
$ cd C:\hadoop-3.3.2\sbin
$ start-dfs.cmd
```
start-dfs.cmd을 실행하게되면 namenode, datanode이름의 cmd 두 개가 실행된다
7. hdfs web ui 접속
인터넷 url에 http://localhost:9870/ 을 입력
8. yarn 실행
실행하면 resourcemanager, nodemanager cmd창 두 개가 실행된다
9. resource manage web ui
http://localhost:8088/
10. 예제 실행
```
$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.2.jar pi 16 10000
```

오류!  
위의 예제 실행 중 메모리가 할당되지 않아 시작되지 않고 계속 대기중으로 뜬다,,,
